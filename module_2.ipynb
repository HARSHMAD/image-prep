{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "square = np.zeros((300,300),np.uint8)\n",
    "rectangle = cv2.rectangle(square,(50,50),(250,250),255,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imshow('square',square)\n",
    "cv2.imshow('rec',rectangle)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ellipse = np.zeros((300,300),np.uint8)\n",
    "cv2.ellipse(ellipse,(150,150),(150,150),30,0,180,255,-1)\n",
    "cv2.imshow(\"ellipse\",ellipse)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AND_shows only where the two intersect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bitwise_and = cv2.bitwise_and(square,ellipse)\n",
    "cv2.imshow('AND',bitwise_and)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " OR_shows only where either square or ellipse is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bitwise_or = cv2.bitwise_or(square,ellipse)\n",
    "cv2.imshow('OR',bitwise_or)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XOR_shows only where either exists by itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bitwise_xor = cv2.bitwise_xor(square,ellipse)\n",
    "cv2.imshow('XOR',bitwise_xor)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOT_shows everything that’s not part of the ellipse and NOT operation can be applied only to single figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bitwise_not = cv2.bitwise_not(ellipse)\n",
    "cv2.imshow('NOT',bitwise_not)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution & Blurring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A convolution is an mathematical operation performed on two functions producing a third function which is typically a modified version of original function.\n",
    "In computer vision we use kernel’s to specify the size over which we run our manipulating function over our image.\n",
    "Blurring is an operation where we average the pixels within a region(Kernel)\n",
    "\n",
    "OpenCV blurs an image by applying kernels, a kernel tells you how to change the value of any given pixel by combining it with different amount of neighboring pixels the kernel is applied to every pixel in the image one by one to produce the final image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = cv2.imread(r'C:\\Users\\Celebal\\Desktop\\input.jpg')\n",
    "cv2.imshow(\"image\",image)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a 3x3 kernel matrix\n",
    "kernel = np.ones((3,3),np.float32)/9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a 7x7 kernel matrix\n",
    "kernel2 = np.ones((7,7),np.float32)/49\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cv2.filter2D to convolve the kernel with an image\n",
    "blurred = cv2.filter2D(image,-1,kernel)\n",
    "cv2.imshow(\"blurred\",blurred)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cv2.filter2D to convolve the kernel with an image\n",
    "blurred2 = cv2.filter2D(image,-1,kernel2)\n",
    "cv2.imshow(\"blurred\",blurred2)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# other types of blurring methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cv2.blur – Averages value over a specified window.\n",
    "\n",
    "cv2.GaussianBlur – Similar but uses a Gaussian window (more emphasis on points around the center).\n",
    "\n",
    "cv2.medianBlur– Uses median of all elements in the window.\n",
    "\n",
    "cv2.bilateralFilter– Blurs while keeping the edges sharp, it preserves the edges and line details.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cv2.blur:In this method averaging is done by convolving the image with a normalized box filter, this takes the place under the box and replaces the central element. Here the box size needs to be odd and positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#implementation of cv2blur\n",
    "blur = cv2.blur(image,(3,3))\n",
    "cv2.imshow(\"blur\",blur)\n",
    "cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#implementation of gaussian blur\n",
    "Gauss = cv2.GaussianBlur(image,(7,7),0)\n",
    "cv2.imshow('gaussian_blur',Gauss)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### implementation of median \n",
    "median = cv2.medianBlur(image,5)\n",
    "cv2.imshow('median_blur',median)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#implementation of bilateral filter\n",
    "bilateral = cv2.bilateralFilter(image,9,80,80)\n",
    "cv2.imshow('bilateral',bilateral)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sharpening - Reversing the image blurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sharpening is the opposite of blurring, it strengths or emphasizes on edges in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_sh = np.ones((3,3),np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [1., 1., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel_sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_sharp = np.negative(kernel_sharp)\n",
    "kernel_sharp[1,1] = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sharpen = cv2.filter2D(image,-1,kernel_sharp)\n",
    "cv2.imshow(\"sharp_image\",sharpen)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Threshoding (Binarization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thresholding is act of converting an image into binary form. In opencv there is separate function for thresholding defined as\n",
    "\n",
    "Cv2.threshold(image, threshold value, Max value, threshold type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = cv2.imread(r'C:\\Users\\Celebal\\Desktop\\input.jpg',0)\n",
    "cv2.imshow(\"original\",image)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_,thresh1=cv2.threshold(image,127,220,cv2.THRESH_BINARY)\n",
    "cv2.imshow('1 threshold',thresh1)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dilation, Erosion, Opening/Closing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dilation – it adds pixels to the boundaries of object in an image.\n",
    "\n",
    "Erosion – Removes pixels at the boundaries of object in an image.\n",
    "\n",
    "Opening – Erosion followed by dilation.\n",
    "\n",
    "Closing – Dilation followed by erosion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion with dilation and erosion\n",
    "\n",
    "There is sometimes confusion between dilation and erosion usually in pictures with white background, as opencv considers white background as image to be dilated or eroded instead of original picture, so in this case erosion works as dilation and vice-versa, as shown in image sample shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "image2 = cv2.imread(r'C:\\Users\\Celebal\\Desktop\\capture.png')\n",
    "cv2.imshow('img',image2)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kernel\n",
    "kernel = np.ones((5,5),np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#erode\n",
    "erosion=cv2.erode(image2,kernel,iterations=1)\n",
    "cv2.imshow('Erosion',erosion)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##dilation\n",
    "dilate = cv2.dilate(image2,kernel,iterations =1)\n",
    "cv2.imshow('dilation',dilate)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Opening\n",
    "opening = cv2.morphologyEx(image2,cv2.MORPH_OPEN,kernel)\n",
    "cv2.imshow('opening',opening)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#closing\n",
    "closing = cv2.morphologyEx(image2,cv2.MORPH_CLOSE,kernel)\n",
    "cv2.imshow('closing',closing)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edge detection and Image gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formally Edges can be defined as sudden changes (discontinuities) in an image and they can encode as much information as pixels.\n",
    "\n",
    "Edge detection algorithms:- There are three main types of edge detection algorithms\n",
    "\n",
    "Sobel – to emphasis on vertical or horizontal images.\n",
    "\n",
    "Laplacian – optimal due to low error rate, well defined edges and accurate detection.\n",
    "\n",
    "Canny Edge detection algorithm (devolped by john.F.Canny in 1986)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "image = cv2.imread(r'C:\\Users\\Celebal\\Desktop\\11.png',0)\n",
    "height,width = image.shape[:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imshow('image',image)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sobel\n",
    "sobel_x = cv2.Sobel(image,cv2.CV_64F,0,1,ksize =5)\n",
    "sobel_y = cv2.Sobel(image,cv2.CV_64F,1,0,ksize = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imshow(\"sobelx\",sobel_x)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imshow('sobely',sobel_y)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sobel_or = cv2.bitwise_or(sobel_x,sobel_y)\n",
    "cv2.imshow('sobel_or',sobel_or)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#laplian\n",
    "laplace = cv2.Laplacian(image,cv2.CV_64F)\n",
    "cv2.imshow(\"laplace\",laplace)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cany\n",
    "cany = cv2.Canny(image,80,120)\n",
    "cv2.imshow(\"cany\",cany)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
